{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision  import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "device=torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Augmentation\n",
    "transform = transforms.Compose([\n",
    "\ttransforms.RandomRotation(10),\n",
    "\ttransforms.RandomHorizontalFlip(),\n",
    "\ttransforms.ToTensor(),\n",
    "\ttransforms.Normalize((0.5,), (0.5,))\n",
    "    \n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=torchvision.datasets.FashionMNIST(root='data',download=False,train=True,transform=transform)\n",
    "test_dataset=torchvision.datasets.FashionMNIST(root=\"data\",download=False,train=False,transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=DataLoader(train_dataset,batch_size=64,shuffle=True)\n",
    "test_loader=DataLoader(test_dataset,batch_size=64,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the Resnet-18 weights\n",
    "model=models.resnet18(weights='ResNet18_Weights.DEFAULT')\n",
    "#Adjusting for input grey scale\n",
    "model.conv1=nn.Conv2d(in_channels=1,out_channels=64,kernel_size=3,stride=1,padding=1,bias=False)\n",
    "model.bn1=nn.BatchNorm2d(64)\n",
    "model.fc=nn.Linear(model.fc.in_features,10)#as there are 10 classes in FashionMNIST\n",
    "model=model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "optimizer=optim.Adam(model.parameters(),lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.44597237296640746\n",
      "Epoch: 1, Loss: 0.3057473830259177\n",
      "Epoch: 2, Loss: 0.26318658511045134\n",
      "Epoch: 3, Loss: 0.24193304436388555\n",
      "Epoch: 4, Loss: 0.2253847660413429\n",
      "Epoch: 5, Loss: 0.20929143402669856\n",
      "Epoch: 6, Loss: 0.19557377837423576\n",
      "Epoch: 7, Loss: 0.18341394389536717\n",
      "Epoch: 8, Loss: 0.1720072875148865\n",
      "Epoch: 9, Loss: 0.1695715296588568\n",
      "Epoch: 10, Loss: 0.1523923664562293\n",
      "Epoch: 11, Loss: 0.14710347333958726\n",
      "Epoch: 12, Loss: 0.13649687780015696\n",
      "Epoch: 13, Loss: 0.13014729221714838\n",
      "Epoch: 14, Loss: 0.12540916416214218\n",
      "Epoch: 15, Loss: 0.11721936811003954\n",
      "Epoch: 16, Loss: 0.10841615159096303\n",
      "Epoch: 17, Loss: 0.10261781455408822\n",
      "Epoch: 18, Loss: 0.09854329702978544\n",
      "Epoch: 19, Loss: 0.093036076212838\n",
      "Epoch: 20, Loss: 0.08593201998676826\n",
      "Epoch: 21, Loss: 0.08266794583154545\n",
      "Epoch: 22, Loss: 0.07985315681683389\n",
      "Epoch: 23, Loss: 0.07922484677062551\n",
      "Epoch: 24, Loss: 0.0718055572519615\n",
      "Epoch: 25, Loss: 0.06672534948266519\n",
      "Epoch: 26, Loss: 0.06495553454054571\n",
      "Epoch: 27, Loss: 0.06175552689726514\n",
      "Epoch: 28, Loss: 0.061368212002321586\n",
      "Epoch: 29, Loss: 0.05707012353090645\n",
      "Epoch: 30, Loss: 0.05383869863625592\n"
     ]
    }
   ],
   "source": [
    "#Training loop\n",
    "num_epochs=100\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss=0\n",
    "    for images, labels in train_loader:\n",
    "        images,labels=images.to(device),labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs=model(images)\n",
    "        loss=criterion(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss+=loss.item()\n",
    "\n",
    "    print(f\"Epoch: {epoch}, Loss: {total_loss/len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 63.28\n"
     ]
    }
   ],
   "source": [
    "#Testing loop\n",
    "model.eval()\n",
    "correct=0\n",
    "total=0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images,labels=images.to(device),labels.to(device)\n",
    "        outputs=model(images)\n",
    "        _,predicted=torch.max(outputs.data,1)\n",
    "        total+=labels.size(0)\n",
    "        correct+=(predicted==labels).sum().item()\n",
    "accuracy=correct*100/total\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/10, Loss: 0.0651\n",
      "Accuracy: 65.21\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (10,) and (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 44\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Plotting\u001b[39;00m\n\u001b[1;32m     43\u001b[0m ax1\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m---> 44\u001b[0m \u001b[43max1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_losses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmarker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mo\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[1;32m     45\u001b[0m ax2\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m     46\u001b[0m ax2\u001b[38;5;241m.\u001b[39mplot(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m), test_accuracy, marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mo\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/code/solo projects/Mammography-project/MAM1/lib/python3.12/site-packages/matplotlib/axes/_axes.py:1777\u001b[0m, in \u001b[0;36mAxes.plot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1534\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1535\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[1;32m   1536\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1776\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[0;32m-> 1777\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[1;32m   1778\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[1;32m   1779\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[0;32m~/Desktop/code/solo projects/Mammography-project/MAM1/lib/python3.12/site-packages/matplotlib/axes/_base.py:297\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[0;34m(self, axes, data, return_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    295\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    296\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 297\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_kwargs\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/code/solo projects/Mammography-project/MAM1/lib/python3.12/site-packages/matplotlib/axes/_base.py:494\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[0;34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    491\u001b[0m     axes\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mupdate_units(y)\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m--> 494\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    495\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    496\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    498\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (10,) and (1,)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Training loop with realtime plotting \n",
    "num_epochs=10\n",
    "train_losses=[]\n",
    "test_accuracy=[]\n",
    "plt.ion()\n",
    "fig, (ax1,ax2)=plt.subplots(1,2,figsize=(10,5))\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss=0\n",
    "    for images, labels in train_loader:\n",
    "        images,labels=images.to(device),labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs=model(images)\n",
    "        loss=criterion(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss+=loss.item()\n",
    "\n",
    "avg_loss=total_loss/len(train_loader)\n",
    "train_losses.append(avg_loss)\n",
    "print(f\"Epoch: {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "# Evaluate on test set\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "accuracy = correct * 100 / total\n",
    "test_accuracy.append(accuracy)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "\n",
    "\n",
    "# Plotting\n",
    "ax1.clear()\n",
    "ax1.plot(range(1, epoch + 2), train_losses, marker='o') \n",
    "ax2.clear()\n",
    "ax2.plot(range(1, epoch + 2), test_accuracy, marker='o')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Training Loss per Epoch')\n",
    "ax1.legend()\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax2.set_ylabel('Accuracy (%)')\n",
    "ax2.set_title('Test Accuracy per Epoch')\n",
    "ax2.legend()\n",
    "\n",
    "plt.pause(0.1)\n",
    "plt.ioff()\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MAM1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
